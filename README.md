# Paper-review
- Start on June 29, 2024


## Fine-grained classification with zero shot learning
- Attention을 기반으로 한 방법이 많으며, 최근에 나온 I2DFormer의 경우 human annotation 필요 없이 document를 이용해 attribute 대체
- Fine-Grained Zero-Shot Learning: Advances, Challenges, and Prospects(NIPS2024) [[Paper]](https://arxiv.org/pdf/2401.17766)[[Review]](https://fluoridated-trust-1fc.notion.site/Fine-Grained-Zero-Shot-Learning-Advances-Challenges-and-Prospects-1279c7dcb9c4805e8b45e65dc166b7af?pvs=4)
-MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning (CVPR2022)
[[Paper]](https://arxiv.org/pdf/2203.03137)[[GitHub]](https://github.com/shiming-chen/MSDN)[[Review]](https://fluoridated-trust-1fc.notion.site/MSDN-Mutually-Semantic-Distillation-Network-for-Zero-Shot-Learning-1299c7dcb9c48038845bfa4063b6469f?pvs=4)
- I2DFormer: Learning Image to Document Attention (CVPR2023)
for Zero-Shot Image Classification
 [[Paper]](https://arxiv.org/abs/2209.10304)[[GitHub]](https://github.com/ferjad/I2DFormer)[[Review]](https://fluoridated-trust-1fc.notion.site/I2DFormer-Learning-Image-to-Document-Attention-for-Zero-Shot-Image-Classification-1299c7dcb9c48033a941c8e318876524?pvs=4)
- TransZero: Attribute-guided Transformer for Zero-Shot Learning (2021) [[Paper]](https://arxiv.org/pdf/2112.01683)[[Review]](https://fluoridated-trust-1fc.notion.site/TransZero-Attribute-guided-Transformer-for-Zero-Shot-Learning-1299c7dcb9c48035b0c9ea513c474022?pvs=4)
- Fine-Grained Generalized Zero-shot Learning via Dense Attribute-Based Attention (CVPR2020) [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Huynh_Fine-Grained_Generalized_Zero-Shot_Learning_via_Dense_Attribute-Based_Attention_CVPR_2020_paper.pdf)[[GitHub]](https://github.com/hbdat/cvpr20_DAZLE)[[Review]](https://github.com/hbdat/cvpr20_DAZLE)

<!-- [[Paper]]()[[GitHub]]()[[Review]]()-->

## Bias Mitigation
- Co2PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning [[Paper]](https://aclanthology.org/2023.findings-emnlp.390/)[[GitHub]](https://github.com/dongxiangjue/Co2PT)[[Review]](https://fluoridated-trust-1fc.notion.site/Co2PT-Mitigating-Bias-in-Pre-trained-Language-Models-through-Counterfactual-Contrastive-Prompt-Tuni-47f53112fa814c22ab2750404b8e65e1)

## Fine tunning

## Multimodality

## RAG
- Question-Based Retrieval using Atomic Units for Enterprise RAG [[Paper]](https://arxiv.org/pdf/2405.12363v2)[[GitHub]]()[[Review]]()

## Self-supervised Learning
- SimCLR: A Simple Framework for Contrastive Learning of Visual Representations [[Paper]](https://arxiv.org/abs/2002.05709)[[Review]](https://fluoridated-trust-1fc.notion.site/SimCLR-A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations-6adee112129e4a24a4ff59c1ea16b3d4?pvs=4)
